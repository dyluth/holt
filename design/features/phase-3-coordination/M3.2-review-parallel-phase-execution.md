# **Feature design: Review & Parallel Phase Execution**

**Purpose**: Enable review and parallel phase execution with multi-agent coordination
**Scope**: Phase 3 Coordination - Milestone 2
**Estimated tokens**: ~5,000 tokens
**Read when**: Implementing review/parallel phases, multi-phase workflows, phase transitions

Associated phase: **Coordination (Phase 3)**
Status: **Draft**

***Template purpose:*** This document is a blueprint for M3.2, an implementable milestone that builds on M3.1's consensus bidding to add review and parallel phase execution. It provides an unambiguous specification for implementing the full three-phase claim lifecycle (review → parallel → exclusive).

## **1. The 'why': goal and success criteria**

### **1.1. Goal statement**

Enable the orchestrator to execute review and parallel phases of the claim lifecycle, allowing multiple agents to review work before execution and multiple agents to work in parallel on the same artefact, completing the three-phase workflow model.

### **1.2. User story**

As a Sett user, I want to define multiple specialized agents in my sett.yml (e.g., a code-reviewer agent, a coder agent, and a test agent) with different bidding strategies (review, claim, exclusive) so that when I run `sett forage --goal "implement feature X"`, the orchestrator:
1. Grants the claim to review agents first (review phase)
2. Waits for all review agents to complete and approve the work
3. If any reviewer provides feedback, terminates the claim and stops the workflow
4. If all reviewers approve, grants the claim to parallel agents (parallel phase)
5. Waits for all parallel agents to complete their work
6. Finally grants the claim to the exclusive agent (exclusive phase)
7. Transitions the claim to `complete` status

This ensures proper work validation, enables concurrent task execution, and maintains a clear audit trail of which agents participated in which phases.

### **1.3. Success criteria**

1. **Review phase execution**: 2 agents bid "review", both get granted, both produce Review artefacts with `{}` payload → claim transitions to `pending_parallel`
2. **Review rejection (single veto)**: 1 agent bids "review", produces Review artefact with feedback payload → claim transitions to `terminated`
3. **Multiple reviewers with veto**: 3 agents bid "review", 2 approve (`{}`), 1 rejects (feedback) → claim transitions to `terminated` (single veto)
4. **Parallel phase execution**: 2 agents bid "claim", both get granted, both produce artefacts → claim transitions to `pending_exclusive`
5. **Phase skipping - no review**: Zero "review" bids → claim immediately transitions to `pending_parallel`
6. **Phase skipping - no parallel**: Zero "claim" bids → claim immediately transitions to `pending_exclusive`
7. **Full 3-phase workflow**: review (all approve) → parallel (all complete) → exclusive (completes) → claim status `complete`
8. **Backward compatibility**: M3.1 exclusive-only workflows continue to work (phase skipping to exclusive)
9. **Audit trail**: `sett hoard` shows which agents participated in which phases, with clear phase progression logs
10. **Unique role validation**: `sett up` fails if multiple agents have the same role, with clear error message

### **1.4. Non-goals**

- **Orchestrator restart resilience** (Future): If orchestrator crashes mid-phase, claim state is lost and claim becomes stuck
- **Automated feedback loop** (Future): Review rejection terminates claim; no automatic retry with feedback incorporated
- **Runtime failure detection** (Future): Agents that crash during execution leave claims waiting indefinitely
- **Phase execution timeouts** (Future): No timeout for granted agents to produce artefacts
- **Parallel agent coordination hints** (Future): Agents are assumed to perform non-conflicting work
- **LLM-based phase decisions** (Phase 4): Phase transitions are deterministic based on artefact presence/content
- **Dynamic phase ordering** (Future): Phase order is fixed: review → parallel → exclusive

## **2. The 'what': component impact analysis**

### **2.1. Blackboard changes**

**No schema changes required**: The existing Claim and Artefact data structures already support the three-phase model. The Claim struct has:
- `Status`: Supports all phase states (pending_review, pending_parallel, pending_exclusive, complete, terminated)
- `GrantedReviewAgents`: Array for tracking review phase grants
- `GrantedParallelAgents`: Array for tracking parallel phase grants
- `GrantedExclusiveAgent`: String for tracking exclusive phase grant

**Enhanced logging events:**
- Phase transition events (review→parallel, parallel→exclusive, etc.)
- Review feedback detection events
- Phase completion events with duration tracking
- Grant notifications now include `claim_type` field

### **2.2. Orchestrator changes**

**Major enhancement**: The orchestrator gains phase execution logic and state tracking.

#### **2.2.1. Phase state tracking (in-memory)**

```go
type PhaseState struct {
    ClaimID            string
    Phase              string // "review", "parallel", "exclusive"
    GrantedAgents      []string
    ReceivedArtefacts  map[string]string // agentRole → artefactID
    StartTime          time.Time
}

// In orchestrator engine
phaseStates map[string]*PhaseState // claimID → PhaseState
```

**Limitation**: This in-memory state is lost on orchestrator restart. Claims in active phases will become stuck. This is documented as a known limitation and will be addressed in a future milestone.

#### **2.2.2. Enhanced grant flow**

After consensus is achieved, the orchestrator:

1. **Determine initial phase** based on bid types:
   ```go
   hasReviewBids := countBidType(bids, "review") > 0
   hasParallelBids := countBidType(bids, "claim") > 0
   hasExclusiveBids := countBidType(bids, "exclusive") > 0

   // Phase skipping logic
   if !hasReviewBids {
       if !hasParallelBids {
           // Skip directly to exclusive
           claim.Status = "pending_exclusive"
       } else {
           // Skip to parallel
           claim.Status = "pending_parallel"
       }
   } else {
       // Start with review
       claim.Status = "pending_review"
   }
   ```

2. **Grant to appropriate phase agents**:
   ```go
   switch claim.Status {
   case "pending_review":
       grantReviewPhase(claim, bids)
   case "pending_parallel":
       grantParallelPhase(claim, bids)
   case "pending_exclusive":
       grantExclusivePhase(claim, bids) // M3.1 existing logic
   }
   ```

3. **Initialize phase tracking**:
   ```go
   phaseState := &PhaseState{
       ClaimID: claim.ID,
       Phase: determinePhase(claim.Status),
       GrantedAgents: extractGrantedAgents(claim, phase),
       ReceivedArtefacts: make(map[string]string),
       StartTime: time.Now(),
   }
   phaseStates[claim.ID] = phaseState
   ```

#### **2.2.3. Artefact event processing**

The orchestrator subscribes to `artefact_events` channel (existing) and adds phase completion detection:

```go
func (e *Engine) processArtefactForPhases(ctx context.Context, artefact *blackboard.Artefact) {
    // Skip non-phase-relevant artefacts
    if artefact.StructuralType == blackboard.StructuralTypeTerminal ||
       artefact.StructuralType == blackboard.StructuralTypeFailure {
        return
    }

    // Find claims waiting for artefacts from this producer
    for claimID, phaseState := range e.phaseStates {
        claim, err := e.client.GetClaim(ctx, claimID)
        if err != nil || claim.ArtefactID != artefact.SourceArtefacts[0] {
            continue // Not related to this claim
        }

        // Check if this artefact is from a granted agent
        if isGrantedAgent(claim, artefact.ProducedByRole, phaseState.Phase) {
            phaseState.ReceivedArtefacts[artefact.ProducedByRole] = artefact.ID

            // Check phase completion
            e.checkPhaseCompletion(ctx, claim, phaseState, artefact)
        }
    }
}
```

#### **2.2.4. Review phase completion logic**

```go
func (e *Engine) checkReviewPhaseCompletion(ctx context.Context, claim *blackboard.Claim, phaseState *PhaseState) {
    // Check if all granted review agents have submitted
    if len(phaseState.ReceivedArtefacts) < len(phaseState.GrantedAgents) {
        return // Still waiting for reviews
    }

    // Fetch all Review artefacts and check for feedback
    hasFeedback := false
    for agentRole, artefactID := range phaseState.ReceivedArtefacts {
        artefact, err := e.client.GetArtefact(ctx, artefactID)
        if err != nil {
            e.logError("failed to fetch review artefact", err)
            continue
        }

        // Parse review payload
        if !isApproval(artefact.Payload) {
            hasFeedback = true
            e.logEvent("review_rejection", map[string]interface{}{
                "claim_id": claim.ID,
                "reviewer": agentRole,
                "artefact_id": artefact.ID,
            })
            break // Single veto
        }
    }

    if hasFeedback {
        // Terminate claim
        claim.Status = blackboard.ClaimStatusTerminated
        e.client.UpdateClaim(ctx, claim)
        delete(e.phaseStates, claim.ID)
        e.logEvent("claim_terminated_review_feedback", map[string]interface{}{
            "claim_id": claim.ID,
        })
    } else {
        // All approved - transition to next phase
        e.transitionToNextPhase(ctx, claim, phaseState)
    }
}
```

#### **2.2.5. Review payload parsing (robust)**

```go
func isApproval(payload string) bool {
    // Attempt to parse as JSON
    var jsonData interface{}
    err := json.Unmarshal([]byte(payload), &jsonData)
    if err != nil {
        // Not valid JSON → feedback
        return false
    }

    // Check if empty object or empty array
    switch v := jsonData.(type) {
    case map[string]interface{}:
        return len(v) == 0 // {} = approval
    case []interface{}:
        return len(v) == 0 // [] = approval
    default:
        return false // Any other JSON type = feedback
    }
}
```

**Edge cases:**
- `{}` → approval (empty object)
- `[]` → approval (empty array)
- `{"issue": "fix this"}` → feedback (non-empty object)
- `["problem"]` → feedback (non-empty array)
- `""` → feedback (empty string, not JSON)
- `"true"` → feedback (JSON boolean, not object/array)
- `42` → feedback (JSON number)
- Invalid JSON → feedback

#### **2.2.6. Parallel phase completion logic**

```go
func (e *Engine) checkParallelPhaseCompletion(ctx context.Context, claim *blackboard.Claim, phaseState *PhaseState) {
    // Check if all granted parallel agents have produced artefacts
    if len(phaseState.ReceivedArtefacts) < len(phaseState.GrantedAgents) {
        return // Still waiting
    }

    // All parallel agents completed - transition to exclusive
    e.logEvent("parallel_phase_complete", map[string]interface{}{
        "claim_id": claim.ID,
        "duration_ms": time.Since(phaseState.StartTime).Milliseconds(),
        "agents": phaseState.GrantedAgents,
    })

    e.transitionToNextPhase(ctx, claim, phaseState)
}
```

#### **2.2.7. Phase transition logic (atomic)**

```go
func (e *Engine) transitionToNextPhase(ctx context.Context, claim *blackboard.Claim, phaseState *PhaseState) {
    // Atomic check: Fetch current claim status from Redis
    currentClaim, err := e.client.GetClaim(ctx, claim.ID)
    if err != nil {
        e.logError("failed to fetch claim for transition", err)
        return
    }

    // Verify status hasn't changed (prevents double-transition)
    if currentClaim.Status != claim.Status {
        e.logEvent("phase_transition_skipped", map[string]interface{}{
            "claim_id": claim.ID,
            "expected_status": claim.Status,
            "actual_status": currentClaim.Status,
        })
        return
    }

    // Determine next phase
    var nextStatus blackboard.ClaimStatus
    switch currentClaim.Status {
    case blackboard.ClaimStatusPendingReview:
        // Check if parallel phase has bids
        if hasParallelBids(phaseState.AllBids) {
            nextStatus = blackboard.ClaimStatusPendingParallel
        } else if hasExclusiveBids(phaseState.AllBids) {
            nextStatus = blackboard.ClaimStatusPendingExclusive
        } else {
            // No more work - claim becomes dormant
            e.logEvent("claim_dormant", map[string]interface{}{
                "claim_id": claim.ID,
            })
            delete(e.phaseStates, claim.ID)
            return
        }

    case blackboard.ClaimStatusPendingParallel:
        // Check if exclusive phase has bids
        if hasExclusiveBids(phaseState.AllBids) {
            nextStatus = blackboard.ClaimStatusPendingExclusive
        } else {
            // No exclusive work - claim becomes dormant
            e.logEvent("claim_dormant", map[string]interface{}{
                "claim_id": claim.ID,
            })
            delete(e.phaseStates, claim.ID)
            return
        }

    case blackboard.ClaimStatusPendingExclusive:
        // Exclusive completes → claim complete (M3.1 existing behavior)
        nextStatus = blackboard.ClaimStatusComplete
        delete(e.phaseStates, claim.ID)
    }

    // Update claim status
    currentClaim.Status = nextStatus
    err = e.client.UpdateClaim(ctx, currentClaim)
    if err != nil {
        e.logError("failed to update claim status", err)
        return
    }

    e.logEvent("phase_transition", map[string]interface{}{
        "claim_id": claim.ID,
        "from_status": claim.Status,
        "to_status": nextStatus,
    })

    // Grant next phase
    e.grantNextPhase(ctx, currentClaim, phaseState)
}
```

#### **2.2.8. Enhanced grant notifications**

Grant notifications now include `claim_type` field to inform agents which phase they're in:

```go
notification := map[string]string{
    "event_type": "grant",
    "claim_id":   claimID,
    "claim_type": claimType, // "review", "claim", or "exclusive"
}
```

This allows agents to adapt their behavior based on the phase (e.g., different prompts for review vs execution).

### **2.3. Agent cub changes**

#### **2.3.1. Loop prevention heuristic refinement**

Update the bidding logic to allow review bids on own outputs:

```go
// handleClaimEvent processes a claim event by submitting a bid.
func (e *Engine) handleClaimEvent(ctx context.Context, claim *blackboard.Claim) {
    // ... existing artefact fetch logic ...

    // Default to configured bidding strategy
    bidType := e.config.BiddingStrategy

    // HEURISTIC: Refined loop prevention for M3.2
    if targetArtefact.ProducedByRole == e.config.AgentRole {
        if e.config.BiddingStrategy == blackboard.BidTypeReview {
            // M3.2: Allow review bids on own outputs (self-review scenario)
            log.Printf("[INFO] Allowing self-review for claim %s (role: %s)", claim.ID, e.config.AgentRole)
        } else {
            // Still block claim/exclusive on own outputs
            log.Printf("[INFO] Ignoring claim %s for self-produced artefact (role: %s)", claim.ID, e.config.AgentRole)
            bidType = blackboard.BidTypeIgnore
        }
    }

    // ... existing bid submission logic ...
}
```

#### **2.3.2. Grant notification handling**

No changes required - cubs already handle grant notifications. The new `claim_type` field is available for future use (Phase 4 LLM prompts).

### **2.4. CLI changes**

No changes required for M3.2. The CLI's `sett up`, `sett forage`, `sett down`, and `sett hoard` commands work unchanged.

### **2.5. Config validation changes**

**New validation rule**: Enforce unique agent roles.

```go
// In internal/config/config.go Validate() method
func (c *SettConfig) Validate() error {
    // ... existing validation ...

    // M3.2: Enforce unique agent roles
    rolesSeen := make(map[string]string) // role → agentName
    for agentName, agent := range c.Agents {
        if existingAgent, exists := rolesSeen[agent.Role]; exists {
            return fmt.Errorf("duplicate agent role '%s' found (agents '%s' and '%s'): all agents must have unique roles in Phase 3",
                agent.Role, existingAgent, agentName)
        }
        rolesSeen[agent.Role] = agentName
    }

    return nil
}
```

**Error message example:**
```
Error: duplicate agent role 'Coder' found (agents 'go-agent' and 'python-agent'): all agents must have unique roles in Phase 3

Please update sett.yml to use unique role names.
```

**Rationale**: With unique roles, `produced_by_role` uniquely identifies which granted agent produced each artefact, enabling reliable phase completion tracking.

## **3. The 'how': implementation & testing plan**

### **3.1. Key design decisions & risks**

**Critical Design Decisions:**

1. **In-Memory Phase State (No Restart Resilience)**:
   - **Decision**: Phase tracking state is kept in-memory, not persisted to Redis
   - **Rationale**: Simplifies M3.2 implementation, avoids Redis schema complexity
   - **Trade-off**: Orchestrator restart loses phase state, claims become stuck
   - **Mitigation**: Document limitation clearly, defer to future milestone
   - **User impact**: Orchestrator must stay running during active workflows

2. **Unique Role Constraint**:
   - **Decision**: All agents must have unique roles
   - **Rationale**: Enables reliable artefact attribution using `produced_by_role`
   - **Trade-off**: Limits flexibility (can't have 2 "Coder" agents)
   - **Mitigation**: Clear validation error, document as Phase 3 constraint
   - **Future resolution**: Phase 4+ could use `produced_by_agent` field

3. **Single Veto Review Logic**:
   - **Decision**: Any single reviewer can terminate claim with feedback
   - **Rationale**: Fail-fast philosophy, prevents bad work from progressing
   - **Trade-off**: Harsh (majority approval not sufficient)
   - **Alternative considered**: Majority vote - rejected as too lenient
   - **User impact**: Review agents must be configured carefully

4. **Robust JSON Parsing for Review Payloads**:
   - **Decision**: Parse JSON, check for empty object/array
   - **Rationale**: Handles whitespace, formatting variations
   - **Trade-off**: More complex than string comparison
   - **Edge case handling**: Non-JSON, numbers, strings all treated as feedback
   - **Fail-safe**: Parsing errors default to feedback (safe)

5. **Phase Skipping vs Dormant Claims**:
   - **Decision**: Skip phases with zero bids, log dormant claims with zero bids in all phases
   - **Rationale**: Enables backward compatibility with M3.1 workflows
   - **Behavior**: Zero review bids → skip to parallel; zero exclusive bids → dormant (log warning)
   - **User visibility**: Clear logs when claims become dormant

6. **Wait Indefinitely for Phase Completion**:
   - **Decision**: No timeout for granted agents to produce artefacts
   - **Rationale**: Consistent with M3.1 consensus waiting, keeps M3.2 simple
   - **Trade-off**: Crashed agents leave claims stuck indefinitely
   - **Mitigation**: Document limitation, defer timeouts to future milestone
   - **Operational impact**: Requires monitoring for stuck claims

**Risks:**

1. **Orchestrator Restart = Lost Phase State**:
   - **Risk**: Production orchestrator restarts mid-workflow, claims become stuck
   - **Probability**: Medium (container restarts, deployments)
   - **Impact**: High (workflows halted, manual intervention required)
   - **Mitigation**: Document clearly, plan restart resilience for future milestone
   - **Monitoring**: Alert on claims in active phases for >30 minutes

2. **Unique Role Constraint Adoption**:
   - **Risk**: Users have existing configs with duplicate roles
   - **Probability**: High (M3.1 didn't enforce this)
   - **Impact**: Medium (breaking change, requires config updates)
   - **Mitigation**: Clear error message with fix guidance, document in upgrade notes
   - **Rollout**: Consider validation warnings before enforcing

3. **Race Condition in Phase Transitions**:
   - **Risk**: Multiple artefacts arrive simultaneously, double-transition attempted
   - **Probability**: Low (single-threaded event loop)
   - **Impact**: Medium (could skip phases or double-grant)
   - **Mitigation**: Atomic Redis status check before transition
   - **Testing**: Concurrent artefact submission tests

4. **Review Payload Parsing Edge Cases**:
   - **Risk**: Unexpected JSON structures cause incorrect approval/rejection
   - **Probability**: Medium (agents may output complex JSON)
   - **Impact**: High (incorrect phase transitions)
   - **Mitigation**: Comprehensive test coverage, strict empty-object/array check
   - **Monitoring**: Log all review payloads for debugging

### **3.2. Implementation steps**

**Phase 1: Config Validation Enhancement**

1. **[Config]** Add unique role validation in `internal/config/config.go` Validate()
2. **[Config]** Write unit tests for duplicate role detection
3. **[Config]** Test error message clarity

**Phase 2: Orchestrator Phase State Management**

4. **[Orchestrator]** Create `internal/orchestrator/phase_state.go`:
   - PhaseState struct definition
   - Phase state tracking map
   - Helper functions: isGrantedAgent(), hasRemainingPhases()

5. **[Orchestrator]** Enhance `internal/orchestrator/engine.go` with artefact processing:
   - Subscribe to artefact_events (already subscribed)
   - Add processArtefactForPhases() handler
   - Track received artefacts per claim

6. **[Orchestrator]** Create `internal/orchestrator/review_phase.go`:
   - grantReviewPhase() function
   - checkReviewPhaseCompletion() logic
   - isApproval() JSON parsing function
   - Review feedback detection and logging

7. **[Orchestrator]** Create `internal/orchestrator/parallel_phase.go`:
   - grantParallelPhase() function
   - checkParallelPhaseCompletion() logic
   - Parallel work completion tracking

8. **[Orchestrator]** Create `internal/orchestrator/phase_transitions.go`:
   - transitionToNextPhase() with atomic Redis check
   - Phase skipping logic
   - Dormant claim detection and logging

9. **[Orchestrator]** Update `internal/orchestrator/granting.go`:
   - Add phase-aware granting logic
   - Determine initial phase from bids
   - Initialize phase state tracking

**Phase 3: Grant Notification Enhancement**

10. **[Orchestrator]** Update publishGrantNotification() in granting.go:
    - Add `claim_type` field to notification JSON
    - Pass "review", "claim", or "exclusive" based on phase

**Phase 4: Agent Cub Loop Prevention Update**

11. **[Cub]** Update handleClaimEvent() in `internal/cub/engine.go`:
    - Refine heuristic to allow review bids on own outputs
    - Keep block on claim/exclusive for own outputs
    - Add clear logging for self-review scenarios

**Phase 5: Testing**

12. **[Tests]** Create `internal/orchestrator/review_phase_test.go`:
    - Unit tests for isApproval() with all edge cases
    - Unit tests for review phase completion detection
    - Unit tests for single veto logic

13. **[Tests]** Create `internal/orchestrator/parallel_phase_test.go`:
    - Unit tests for parallel phase completion tracking
    - Unit tests for multiple parallel agents

14. **[Tests]** Create `internal/orchestrator/phase_transitions_test.go`:
    - Unit tests for phase skipping logic
    - Unit tests for atomic transition checks
    - Unit tests for dormant claim detection

15. **[Tests]** Create `cmd/sett/commands/e2e_phase3_test.go`:
    - E2E test: 3-phase workflow (review→parallel→exclusive)
    - E2E test: Review rejection (single veto)
    - E2E test: Multiple reviewers all approve
    - E2E test: Phase skipping (zero review bids)
    - E2E test: Backward compatibility (M3.1 exclusive-only)

16. **[Tests]** Update `internal/config/config_test.go`:
    - Test unique role validation
    - Test duplicate role error message

**Phase 6: Documentation & Examples**

17. **[Docs]** Update `README.md` with Phase 3 M3.2 status
18. **[Docs]** Create example sett.yml with review/parallel/exclusive agents
19. **[Docs]** Document unique role constraint in upgrade notes
20. **[Docs]** Document M3.2 limitations (restart resilience, timeouts)

### **3.3. Performance & resource considerations**

**Resource usage:**

- **Redis**: Minimal additional load - artefact events already published, no new keys
- **Memory**: Orchestrator stores phase state in-memory (~500 bytes per active claim)
- **CPU**: JSON parsing for review payloads (negligible overhead)
- **Event processing**: Artefact events processed in existing subscription loop

**Scalability limits:**

- **Active claims**: In-memory phase state limits concurrent claims to ~10,000 (assuming 500 bytes each = 5MB)
- **Review agents per claim**: No hard limit, but more reviewers = longer review phase
- **Parallel agents per claim**: No hard limit, tested with 5 parallel agents

**Performance requirements:**

- **Phase transition time**: <100ms from last artefact arrival to status update
- **Review payload parsing**: <1ms per review artefact
- **Artefact event processing**: <10ms per event
- **No regression**: M3.1 exclusive-only workflows maintain same performance

### **3.4. Testing strategy**

**Unit tests:**

1. **Config validation**:
   - Test unique role enforcement
   - Test duplicate role error messages
   - Test backward compatibility (M3.1 configs with unique roles pass)

2. **Review phase logic**:
   - Test isApproval() with all edge cases (see section 2.2.5)
   - Test single veto termination
   - Test all-approve transition
   - Test empty review agent list (phase skipping)

3. **Parallel phase logic**:
   - Test multiple parallel agent completion tracking
   - Test partial completion detection
   - Test empty parallel agent list (phase skipping)

4. **Phase transition logic**:
   - Test atomic status check (prevent double-transition)
   - Test phase skipping (zero bids in phase)
   - Test dormant claim detection
   - Test review→parallel→exclusive progression

**Integration tests:**

1. **Multi-phase orchestrator**:
   - Real Redis + orchestrator
   - Simulate review agents producing artefacts
   - Verify phase transitions
   - Verify grant notifications include claim_type

2. **Agent cub loop prevention**:
   - Test self-review scenario (review bid on own output)
   - Test self-execution blocked (claim/exclusive on own output)

**E2E tests:**

1. **Full 3-phase workflow**:
   ```
   Scenario: review→parallel→exclusive with 3 agents
   Steps:
     1. sett up (3 agents: reviewer, parallel-worker, coder)
     2. sett forage --goal "implement API"
     3. Wait for consensus (all 3 bid appropriately)
     4. Reviewer produces Review artefact with {} (approval)
     5. Verify claim transitions to pending_parallel
     6. Parallel worker produces artefact
     7. Verify claim transitions to pending_exclusive
     8. Coder produces CodeCommit artefact
     9. Verify claim transitions to complete
     10. Verify audit trail shows all 3 phases
   ```

2. **Review rejection test**:
   ```
   Scenario: Single reviewer vetoes work
   Steps:
     1. Reviewer produces Review with {"issue": "needs tests"}
     2. Verify claim transitions to terminated
     3. Verify no further phases execute
     4. Verify clear termination reason in logs
   ```

3. **Multiple reviewers with veto**:
   ```
   Scenario: 3 reviewers, 1 rejects
   Steps:
     1. Reviewer-1 produces {} (approve)
     2. Reviewer-2 produces {"issue": "bug"} (reject)
     3. Reviewer-3 produces {} (approve)
     4. Verify claim transitions to terminated (single veto)
   ```

4. **Phase skipping test**:
   ```
   Scenario: Zero review bids, direct to parallel
   Steps:
     1. No agents bid "review"
     2. 1 agent bids "claim", 1 bids "exclusive"
     3. Verify claim starts in pending_parallel (skips review)
     4. Verify workflow completes normally
   ```

5. **Backward compatibility test**:
   ```
   Scenario: M3.1 exclusive-only workflow
   Steps:
     1. Single agent with bidding_strategy: exclusive
     2. Zero review/parallel bids
     3. Verify claim skips to pending_exclusive
     4. Verify workflow completes as in M3.1
   ```

## **4. Principle compliance check**

### **4.1. YAGNI (You Ain't Gonna Need It)**

**No new third-party dependencies introduced.**

All functionality uses existing libraries:
- Go standard library for JSON parsing
- Existing Redis client for phase state queries
- Existing event subscription mechanisms

**Deferred features:**
- Orchestrator restart resilience (future milestone)
- Automated feedback loop (future milestone)
- Runtime failure timeouts (future milestone)
- Parallel agent coordination hints (Phase 4)

**Justification**: Review and parallel phase execution are core Phase 3 requirements. In-memory phase tracking is the simplest approach that enables M3.2's goals while deferring restart resilience complexity.

### **4.2. Auditability**

**New artefacts created:**
- Review artefacts (already supported by structural_type: Review)
- No new artefact types introduced

**Immutable audit trail enhanced:**
- All review artefacts stored immutably in Redis
- Phase transition events logged with timestamps
- Grant decisions logged with phase information (claim_type field)
- Review feedback logged with reviewer identity

**State changes captured:**
- Phase start: Logged with granted agents list
- Artefact received: Logged with producer and claim association
- Phase completion: Logged with duration and outcome
- Review rejection: Logged with reviewer and feedback artefact ID
- Phase transition: Logged with from/to status

### **4.3. Small, single-purpose components**

**Component responsibilities remain clear:**

- **Orchestrator**: Adds phase execution coordination (natural extension of claim lifecycle management)
- **Agent Cub**: Minimal change (refined loop prevention heuristic)
- **Config**: Adds unique role validation (natural extension of existing validation)

**No tight coupling introduced:**
- Components still communicate only via blackboard (Redis)
- Agent cubs unaware of phase progression (orchestrator-managed)
- Phase state is orchestrator-internal (not exposed via APIs)

**Responsibilities preserved:**
- Orchestrator remains "traffic cop" (no domain logic in phase transitions)
- Agent cubs remain autonomous (no phase-specific behavior changes)
- Config remains declarative validation layer

### **4.4. Security considerations**

**No new security implications:**

- All communication via existing Redis channels (no new network exposure)
- Phase state is in-memory, not exposed externally
- Review payload parsing uses safe JSON unmarshaling (no code injection)

**Data validation:**
- Review payloads validated as JSON before processing
- Phase state changes validated against Redis (atomic checks)
- Grant notifications follow existing security model

### **4.5. Backward compatibility**

**Breaking changes:**

1. **Unique role constraint**:
   - **Breaking**: M3.1 configs with duplicate roles will fail validation
   - **Migration**: Users must rename roles to be unique
   - **Detection**: Clear error message at `sett up` time
   - **Fix effort**: Simple (rename roles in sett.yml)

**Non-breaking changes:**

- Claim status transitions (existing statuses, new usage)
- Grant notifications (additive field: claim_type)
- Artefact events (no schema changes)

**Existing workflows preserved:**

- Single-agent workflows continue working (phase skipping to exclusive)
- Exclusive-only bidding strategies work unchanged (M3.1 behavior)
- All Phase 2 and M3.1 E2E tests must continue passing

### **4.6. Dependency impact**

**Redis usage:**
- More frequent claim status queries (atomic phase transition checks)
- Artefact event processing already exists (no new subscriptions)
- **Impact**: Negligible (additional GET operations are fast)

**Memory usage:**
- Orchestrator stores phase state in-memory
- **Impact**: ~500 bytes per active claim, 10,000 claims = 5MB

**CPU usage:**
- JSON parsing for review payloads
- **Impact**: Negligible (<1ms per review)

**Build dependencies:**
- No changes to Go version or build tools
- **Impact**: None

## **5. Definition of done**

- [ ] All implementation steps from section 3.2 are complete
- [ ] All tests defined in section 3.4 are implemented and passing
- [ ] Performance requirements from section 3.3 are met and verified
- [ ] Overall test coverage has not decreased (maintain 90%+ for new packages)
- [ ] All Phase 2 and M3.1 E2E tests continue passing (backward compatibility)
- [ ] Unique role validation is enforced at `sett up` time
- [ ] Review payload parsing handles all edge cases correctly
- [ ] Phase transition logic is atomic (no race conditions)
- [ ] Grant notifications include claim_type field
- [ ] Agent cub loop prevention allows self-review
- [ ] Example sett.yml with 3-phase workflow created
- [ ] M3.2 limitations are documented in design and README
- [ ] All success criteria from section 1.3 are validated
- [ ] All failure modes identified in section 6 have been tested
- [ ] Operational readiness checklist from section 9 is satisfied

## **6. Error scenarios & edge cases**

### **6.1. Failure modes**

**Orchestrator failures:**

1. **Orchestrator restarts during active phase**:
   - **Behavior**: Phase state lost, claim becomes stuck in current status
   - **Detection**: Claims in pending_* status for >30 minutes
   - **Recovery**: Manual intervention (terminate claim or restart workflow)
   - **Logging**: No automatic logging (state lost on restart)
   - **Mitigation**: Document limitation, plan for future milestone

2. **Redis unavailable during phase transition**:
   - **Behavior**: Transition fails, phase state remains
   - **Detection**: Redis error logged
   - **Recovery**: Retry transition on next artefact arrival
   - **Logging**: "Failed to update claim status: {error}"

3. **Double-transition race condition**:
   - **Behavior**: Atomic Redis check prevents duplicate transition
   - **Detection**: "Phase transition skipped" log event
   - **Recovery**: Automatic (second transition is no-op)
   - **Logging**: Logs expected vs actual claim status

**Agent failures:**

4. **Granted review agent crashes before producing artefact**:
   - **Behavior**: Orchestrator waits indefinitely (M3.2 limitation)
   - **Detection**: Manual monitoring for stuck claims
   - **Recovery**: Manual intervention (restart agent or terminate claim)
   - **Logging**: No automatic timeout detection in M3.2
   - **Future**: Runtime failure detection in future milestone

5. **Review agent produces invalid JSON**:
   - **Behavior**: Treated as feedback, claim terminates
   - **Detection**: JSON parsing error logged
   - **Recovery**: None (interpreted as rejection)
   - **Logging**: "Review payload is not valid JSON, treating as feedback"

6. **Agent produces artefact for wrong claim**:
   - **Behavior**: Artefact not matched to any phase state, ignored
   - **Detection**: Source artefacts don't match any active claim
   - **Recovery**: Automatic (orphaned artefact)
   - **Logging**: No specific logging (artefact just not processed)

**Config failures:**

7. **Duplicate roles in sett.yml**:
   - **Behavior**: Validation fails, `sett up` aborts
   - **Detection**: Config validation during `sett up`
   - **Recovery**: Fix sett.yml (rename roles)
   - **Logging**: "Duplicate agent role 'X' found (agents 'A' and 'B'): all agents must have unique roles in Phase 3"

### **6.2. Concurrency considerations**

**Race condition analysis:**

1. **Multiple Review artefacts arrive simultaneously**:
   - **Possibility**: 2 reviewers produce artefacts at same time
   - **Protection**: Single-threaded event loop processes artefacts sequentially
   - **Impact**: Second artefact may trigger phase completion check
   - **Safety**: Atomic Redis status check prevents double-transition

2. **Phase transition during artefact arrival**:
   - **Possibility**: Artefact arrives while phase transition is in progress
   - **Protection**: Redis claim status checked before processing
   - **Impact**: Artefact may be processed for already-transitioned claim
   - **Safety**: Source artefact check prevents misattribution

3. **Consensus and phase transitions interleaved**:
   - **Possibility**: Consensus grants phase A while phase A is completing
   - **Protection**: Phase state initialized immediately after grant
   - **Impact**: No issue (both operations independent)
   - **Safety**: Phase state map access is single-threaded

### **6.3. Edge case handling**

**Edge case: All agents bid "ignore"**:
- **Behavior**: Zero grants in all phases, claim becomes dormant
- **Detection**: Phase skipping logic reaches end with no grants
- **Recovery**: None (workflow stops, logged)
- **Logging**: "Claim {id} has no grants in any phase, becoming dormant"

**Edge case: Zero review bids, zero parallel bids, one exclusive**:
- **Behavior**: Claim skips directly to pending_exclusive (M3.1 behavior)
- **Detection**: Phase skipping logic in initial phase determination
- **Recovery**: N/A (expected behavior)
- **Logging**: "Skipping review and parallel phases (zero bids), proceeding to exclusive"

**Edge case: All reviewers approve, zero parallel bids**:
- **Behavior**: Claim transitions from pending_review to pending_parallel, then immediately to pending_exclusive
- **Detection**: Phase transition logic detects zero parallel grants
- **Recovery**: N/A (expected behavior)
- **Logging**: Two transition events logged

**Edge case: Review payload is exactly "{}"**:
- **Behavior**: Approval detected, claim proceeds
- **Detection**: JSON parses to empty map
- **Recovery**: N/A (expected behavior)
- **Logging**: "Review approved by {agent}"

**Edge case: Review payload is number 0**:
- **Behavior**: Feedback detected (not object/array), claim terminates
- **Detection**: JSON unmarshals to float64, not map/slice
- **Recovery**: None (terminated)
- **Logging**: "Review feedback detected (non-object/array JSON)"

**Edge case: Review payload is string "{}"**:
- **Behavior**: Feedback detected (JSON string, not object), claim terminates
- **Detection**: JSON unmarshals to string, not map
- **Recovery**: None (terminated)
- **Logging**: "Review feedback detected (JSON string, not object)"

## **7. Open questions & decisions**

**All questions resolved. Ready for implementation.**

The following decisions have been made:

1. ✅ **Review completion detection**: Event-driven via artefact_events subscription
2. ✅ **Review termination**: Stop workflow (no auto-retry in M3.2)
3. ✅ **Multiple reviewers**: Single veto (any rejection terminates)
4. ✅ **Parallel coordination**: User's responsibility (non-conflicting tasks assumed)
5. ✅ **Phase skipping**: Skip phases with zero bids immediately
6. ✅ **Loop prevention**: Allow review on own outputs, block claim/exclusive
7. ✅ **Agent failures**: Wait indefinitely (no timeouts in M3.2)
8. ✅ **Backward compatibility**: M3.1 workflows continue working via phase skipping
9. ✅ **Status transitions**: Confirmed logic (review→parallel→exclusive)
10. ✅ **Unique roles**: Enforced in config validation
11. ✅ **Orchestrator restart**: No resilience in M3.2 (deferred to future)
12. ✅ **Review payload parsing**: Robust JSON parsing (empty object/array = approval)
13. ✅ **Phase transition atomicity**: Single-threaded + atomic Redis status check

## **8. AI agent implementation guidance**

### **8.1. Development approach**

**Start with the simplest path:**
1. Begin with config validation (unique roles)
2. Then orchestrator phase state structures
3. Then review phase logic (most critical)
4. Then parallel phase logic (simpler)
5. Then phase transitions (complex, requires all above)
6. Finally agent cub refinement and testing

**Implement comprehensive error handling from the beginning:**
- All JSON parsing with error handling
- All Redis operations with error handling
- All phase transitions with atomic checks
- Clear logging for all phase events

**Write tests before implementation (TDD approach):**
- Start with unit tests for isApproval() (review payload parsing)
- Then unit tests for phase completion detection
- Then integration tests with real Redis
- Finally E2E tests with full workflows

**Use defensive programming:**
- Always check claim status from Redis before transition
- Validate artefact source matches claim target
- Handle missing phase state gracefully (log warning)
- Never assume phase state exists (may be lost on restart)

### **8.2. Common pitfalls to avoid**

**Orchestrator pitfalls:**

1. **Assuming phase state persistence**:
   - Phase state is in-memory only
   - Always check if phaseState exists before using
   - Handle missing state gracefully (claim may be orphaned)

2. **Not checking claim status atomically**:
   - Always fetch fresh claim from Redis before transition
   - Compare status before updating
   - Log if status has changed (indicates race or double-transition)

3. **Forgetting to delete phase state**:
   - Always delete from phaseStates map when claim completes or terminates
   - Memory leak if not cleaned up

4. **Incorrect artefact attribution**:
   - Match by source_artefacts[0] == claim.ArtefactID
   - Match by produced_by_role == granted agent role
   - Don't assume first artefact is related

**Review phase pitfalls:**

5. **String comparison for review payloads**:
   - Don't use `payload == "{}"` (whitespace sensitive)
   - Always parse as JSON first
   - Check for empty map/slice after parsing

6. **Not implementing single veto**:
   - Don't wait for all reviews before checking feedback
   - Terminate immediately on first rejection
   - Test with multiple reviewers to verify

**Phase transition pitfalls:**

7. **Not handling phase skipping**:
   - Check for zero bids in each phase
   - Skip directly to next phase with grants
   - Handle all-ignore case (dormant claim)

8. **Double-transition on simultaneous artefacts**:
   - Atomic Redis status check required
   - Test with concurrent artefact arrivals
   - Log skipped transitions (helps debugging)

**Config validation pitfalls:**

9. **Allowing duplicate roles**:
   - Must enforce unique roles
   - Check entire config, not just first agent
   - Clear error message with both agent names

### **8.3. Integration checklist**

**Pre-implementation verification:**
- [x] All prerequisite features complete (M3.1)
- [x] No breaking changes to blackboard schema
- [x] Unique role constraint communicated to users
- [x] Phase state structure designed

**During implementation:**
- [ ] Config validation enforces unique roles
- [ ] Review payload parsing tested with all edge cases
- [ ] Phase completion detection tested with multiple agents
- [ ] Phase transitions tested with atomic checks
- [ ] Grant notifications include claim_type field
- [ ] Agent cub loop prevention allows self-review
- [ ] All M3.1 tests still passing

**Post-implementation:**
- [ ] All E2E tests passing (3-phase workflow)
- [ ] Performance benchmarks met
- [ ] Documentation updated (README, limitations)
- [ ] Example sett.yml with 3 agents provided

## **9. Operational readiness**

### **9.1. Monitoring and observability**

**Metrics to track:**

1. **Phase progression metrics**:
   - Time in review phase (milliseconds per claim)
   - Time in parallel phase (milliseconds per claim)
   - Review rejection rate (% of claims terminated in review)
   - Phase skipping frequency (% claims skipping review/parallel)

2. **Phase completion metrics**:
   - Review completion time (milliseconds from grant to all reviews)
   - Parallel completion time (milliseconds from grant to all parallel)
   - Phase transition latency (milliseconds from last artefact to status update)

3. **Review feedback metrics**:
   - Approval rate (% reviews with {} or [])
   - Rejection rate (% reviews with feedback)
   - Invalid JSON rate (% reviews with malformed payloads)

4. **Phase state metrics**:
   - Active phase states (count in-memory)
   - Orphaned phase states (claims in pending_* >30min)
   - Memory usage (bytes for phase state map)

**Structured logging events:**

```json
// Phase start event
{"level":"info","component":"orchestrator","event":"phase_start","claim_id":"abc123","phase":"review","granted_agents":["reviewer-1","reviewer-2"],"timestamp":"2025-10-17T00:00:00Z"}

// Artefact received for phase
{"level":"info","component":"orchestrator","event":"phase_artefact_received","claim_id":"abc123","phase":"review","agent":"reviewer-1","artefact_id":"def456","timestamp":"2025-10-17T00:00:01Z"}

// Review approval
{"level":"info","component":"orchestrator","event":"review_approved","claim_id":"abc123","reviewer":"reviewer-1","artefact_id":"def456","timestamp":"2025-10-17T00:00:01Z"}

// Review rejection
{"level":"warn","component":"orchestrator","event":"review_rejected","claim_id":"abc123","reviewer":"reviewer-2","artefact_id":"ghi789","feedback_summary":"non-empty JSON object","timestamp":"2025-10-17T00:00:02Z"}

// Phase completion
{"level":"info","component":"orchestrator","event":"phase_complete","claim_id":"abc123","phase":"review","duration_ms":1500,"outcome":"approved","timestamp":"2025-10-17T00:00:03Z"}

// Phase transition
{"level":"info","component":"orchestrator","event":"phase_transition","claim_id":"abc123","from_status":"pending_review","to_status":"pending_parallel","timestamp":"2025-10-17T00:00:03Z"}

// Phase skipped
{"level":"info","component":"orchestrator","event":"phase_skipped","claim_id":"abc123","phase":"review","reason":"zero_bids","timestamp":"2025-10-17T00:00:00Z"}

// Dormant claim
{"level":"warn","component":"orchestrator","event":"claim_dormant","claim_id":"abc123","reason":"no_grants_remaining","timestamp":"2025-10-17T00:00:05Z"}
```

**Health check modifications:**
- No changes to orchestrator health endpoint
- Phase state memory usage could be added to /metrics endpoint (future)

**Operator diagnostics:**
- Redis CLI: Inspect claim status
  ```bash
  redis-cli HGET sett:my-instance:claim:abc123 status
  ```
- Orchestrator logs: Grep for phase events
  ```bash
  docker logs sett-orchestrator-my-instance | grep phase_transition
  ```

### **9.2. Rollback and disaster recovery**

**Rollback to M3.1:**

1. **No data migration required**: Blackboard schema unchanged
2. **Config changes**: Remove unique role constraint validation
3. **Orchestrator binary**: Rollback to M3.1 orchestrator image
4. **Behavior**: All claims will use exclusive-only workflow (M3.1)
5. **In-flight claims**: Claims in pending_review/pending_parallel become stuck (must be manually terminated)

**Disaster recovery:**

1. **Orchestrator crash mid-phase**:
   - Phase state lost (in-memory)
   - Claims become stuck in pending_* status
   - **Recovery**: Manually terminate stuck claims, restart workflows
   - **Detection**: Monitor claims in pending_* for >30 minutes

2. **Redis data corruption**:
   - Phase state in-memory (not affected)
   - Claim status in Redis (could be corrupted)
   - **Recovery**: Standard Redis backup/restore procedures
   - **Impact**: May lose claim progression, workflows restart

3. **Agent failures during phase**:
   - Orchestrator waits indefinitely (M3.2 limitation)
   - **Recovery**: Restart failed agents, or manually terminate claims
   - **Detection**: Monitor granted agents with no artefacts produced >10 minutes

**Recovery time objectives:**

- Orchestrator restart: <30 seconds
- Stuck claim detection: <5 minutes (monitoring alerts)
- Manual claim termination: <2 minutes (CLI command)
- Workflow restart: <5 minutes (user re-runs sett forage)

### **9.3. Documentation and training**

**Documentation updates required:**

1. **README.md**:
   - Add Phase 3 M3.2 status badge
   - Update feature list (review/parallel phase execution)
   - Document unique role constraint
   - Document M3.2 limitations (restart resilience, timeouts)

2. **docs/agent-development.md**:
   - Explain review agents and Review artefact format
   - Document `{}` and `[]` approval payloads
   - Explain parallel phase coordination assumptions
   - Example review agent implementation

3. **New guide: docs/multi-phase-workflows.md**:
   - How to design review/parallel/exclusive workflows
   - Review payload formatting guidelines
   - Best practices for parallel agent coordination
   - Debugging phase transitions

4. **Example sett.yml**:
   ```yaml
   # Example: 3-phase workflow with review, parallel, and exclusive agents
   version: "1.0"
   agents:
     reviewer-agent:
       role: "Reviewer"  # Must be unique!
       image: "example-reviewer-agent:latest"
       command: ["/app/run.sh"]
       bidding_strategy: "review"
       workspace:
         mode: ro

     test-agent:
       role: "Tester"  # Must be unique!
       image: "example-test-agent:latest"
       command: ["/app/run.sh"]
       bidding_strategy: "claim"
       workspace:
         mode: ro

     coder-agent:
       role: "Coder"  # Must be unique!
       image: "example-git-agent:latest"
       command: ["/app/run.sh"]
       bidding_strategy: "exclusive"
       workspace:
         mode: rw
   ```

**Troubleshooting guides:**

1. **Common issues**:
   - "Duplicate role error" → Rename roles in sett.yml to be unique
   - "Claim stuck in pending_review" → Check if review agents crashed
   - "Review rejected unexpectedly" → Verify review payload is exactly `{}` or `[]`
   - "Phase skipped when not expected" → Check if agents actually bid for that phase

2. **Debugging commands**:
   ```bash
   # Check claim status
   redis-cli HGET sett:my-instance:claim:abc123 status

   # View orchestrator phase logs
   docker logs sett-orchestrator-my-instance | grep -E "phase_(start|transition|complete)"

   # Check review artefacts
   redis-cli HGETALL sett:my-instance:artefact:def456

   # Monitor stuck claims
   redis-cli KEYS "sett:my-instance:claim:*" | xargs -I {} redis-cli HGET {} status
   ```

**Upgrade notes (M3.1 → M3.2):**

1. **Breaking change**: Unique role constraint
   - Review your sett.yml
   - Ensure all agents have unique roles
   - Rename duplicate roles before upgrading

2. **New behavior**: Phase execution
   - Review agents will now execute and can block work
   - Parallel agents will execute before exclusive
   - Audit `sett hoard` output will show phase progression

3. **Known limitations**:
   - Orchestrator restart loses phase state
   - No automatic retry on review rejection
   - No runtime failure timeouts

## **10. Self-validation checklist**

### **Before starting implementation:**

- [x] I understand how M3.2 builds on M3.1 (adds phase execution)
- [x] All success criteria (section 1.3) are measurable and testable
- [x] I have considered every component in section 2 explicitly
- [x] All design decisions (section 3.1) are justified and documented
- [x] Phase completion detection mechanism is clear (event-driven)
- [x] Review payload parsing rules are unambiguous (JSON parsing)
- [x] Phase transition logic is atomic (Redis status checks)
- [x] Unique role constraint rationale is understood

### **During implementation:**

- [ ] I am implementing the simplest solution that meets success criteria
- [ ] All error scenarios (section 6) are being handled, not just happy path
- [ ] Tests are being written before or alongside code (TDD approach)
- [ ] I am validating that M3.1 functionality is not broken (backward compatibility)
- [ ] Logging is comprehensive (phase events, transitions, review outcomes)
- [ ] Phase state is properly cleaned up (deleted on completion/termination)
- [ ] Atomic Redis checks prevent race conditions
- [ ] Config validation provides clear error messages

### **Before submission:**

- [ ] All items in Definition of Done (section 5) are complete
- [ ] Feature has been tested in a clean environment from scratch
- [ ] Documentation is updated and accurate (README, upgrade notes)
- [ ] I have considered the operational impact (section 9) of this feature
- [ ] All Phase 2 and M3.1 tests pass (backward compatibility validated)
- [ ] E2E tests with 3-phase workflows pass consistently
- [ ] Review rejection tests pass (single veto verified)
- [ ] Phase skipping tests pass (M3.1 workflows work)
- [ ] Example sett.yml with 3 agents provided and tested
- [ ] Unique role validation tested with clear error messages
