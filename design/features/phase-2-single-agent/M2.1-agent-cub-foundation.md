# **Feature design: M2.1 - Agent Pup Foundation**

**Purpose**: Core agent pup binary structure with concurrent architecture foundation
**Scope**: Agent pup component initialization and infrastructure
**Estimated tokens**: ~4,000 tokens

Associated phase: **Single Agent (Phase 2)**
Status: **Draft**

***Template purpose:*** *This document is a blueprint for a single, implementable milestone. Its purpose is to provide an unambiguous specification for a developer (human or AI) to build a feature that is consistent with Holt's architecture and guiding principles.*

## **1. The 'why': goal and success criteria**

### **1.1. Goal statement**

Establish the agent pup binary with its foundational concurrent architecture, configuration management, and health monitoring infrastructure.

### **1.2. User story**

As a Holt developer (human or AI), I need a properly structured agent pup binary that can connect to the blackboard, manage its lifecycle through signals, and provide health status, so that I can build the bidding, execution, and tool integration features on a solid, well-tested foundation.

### **1.3. Success criteria**

* A developer can compile and run `cmd/pup/main.go` with required environment variables, and it successfully connects to Redis and starts running
* The pup exposes a `/healthz` endpoint that returns `200 OK` when connected to Redis and `503 Service Unavailable` otherwise
* The pup responds to SIGINT/SIGTERM signals by gracefully shutting down both goroutines and exiting cleanly within 5 seconds
* The two-goroutine concurrent architecture (Claim Watcher and Work Executor) is fully structured with proper context handling and select loops, even though the work logic is placeholder
* Invalid or missing required environment variables cause the pup to fail fast at startup with clear error messages
* All configuration validation happens before any Redis connection or goroutine launch

**Validation questions:**
* ✅ Can each success criterion be automated as a test? Yes - all are integration-testable
* ✅ Does each criterion represent user-visible value? Yes - enables all subsequent agent development
* ✅ Are the criteria specific enough to avoid ambiguity? Yes - specific technical outcomes defined

### **1.4. Non-goals**

* **NOT in scope**: Pub/Sub subscription to `claim_events` channel (M2.2)
* **NOT in scope**: Bidding logic or bid submission (M2.2)
* **NOT in scope**: Tool execution contract (stdin/stdout) (M2.3)
* **NOT in scope**: Context assembly algorithm (M2.4)
* **NOT in scope**: Git operations or workspace mounting (M2.4)
* **NOT in scope**: Docker container packaging or CLI integration (M2.2)
* **NOT in scope**: Operational mode detection (controller/worker pattern) (Phase 3)
* **NOT in scope**: LLM-specific configuration or prompt handling (M2.3, M2.4)

## **2. The 'what': component impact analysis**

**Critical validation questions for this entire section:**
* ✅ Have I explicitly considered EVERY component (Blackboard, Orchestrator, Pup, CLI)?
* ✅ For components marked "No changes" - am I absolutely certain this feature doesn't affect them?
* ✅ Do my changes maintain the contracts and interfaces defined in the design documents?
* ✅ Will this feature work correctly with both single-instance and scaled agents (controller-worker pattern)?

### **2.1. Blackboard changes**

**New/modified data structures:** No changes

**New Pub/Sub channels:** No changes

**Rationale:** M2.1 only consumes the existing blackboard client (`pkg/blackboard`) established in M1.2. No new blackboard structures or channels are needed. The pup will use the existing `Client` interface for health checks only.

### **2.2. Orchestrator changes**

**New/modified logic:** No changes

**New/modified configurations (holt.yml):** No changes

**Rationale:** M2.1 does not interact with the orchestrator. The orchestrator remains unchanged from M1.5. Integration between pup and orchestrator begins in M2.2 (bidding) and M2.3 (execution).

### **2.3. Agent pup changes**

**New/modified logic:** Complete new component

This milestone creates the entire agent pup component from scratch:

1. **New binary: `cmd/pup/main.go`**
   - Entrypoint for the agent pup process
   - Loads configuration from environment variables
   - Creates and starts the pup engine
   - Sets up signal handling for graceful shutdown
   - Exits with appropriate error codes

2. **New internal package: `internal/pup/config.go`**
   - `Config` struct with required fields:
     * `InstanceName` (from `HOLT_INSTANCE_NAME`)
     * `AgentName` (from `HOLT_AGENT_NAME`)
     * `RedisURL` (from `REDIS_URL`)
   - `LoadConfig()` function to read and validate environment variables
   - `Validate()` method for configuration validation
   - Clear error messages for missing or invalid configuration

3. **New internal package: `internal/pup/engine.go`**
   - `Engine` struct representing the pup's core logic
   - `New(config *Config, bbClient *blackboard.Client)` constructor
   - `Start(ctx context.Context)` method that:
     * Creates the work queue channel (`chan *blackboard.Claim`, buffer size 1)
     * Launches the Claim Watcher goroutine
     * Launches the Work Executor goroutine
     * Waits for context cancellation
     * Returns when all goroutines complete
   - `claimWatcher(ctx context.Context, workQueue chan *blackboard.Claim)` method:
     * Proper select loop structure
     * Placeholder work (logs "Claim Watcher running" periodically)
     * Responds to `ctx.Done()` for graceful shutdown
   - `workExecutor(ctx context.Context, workQueue chan *blackboard.Claim)` method:
     * Proper select loop structure with work queue channel
     * Placeholder work (logs "Work Executor ready" periodically)
     * Responds to `ctx.Done()` for graceful shutdown

4. **New internal package: `internal/pup/health.go`**
   - `HealthServer` struct with HTTP server and blackboard client
   - `NewHealthServer(bbClient *blackboard.Client, port int)` constructor
   - `Start()` method to run HTTP server in background goroutine
   - `Shutdown(ctx context.Context)` method for graceful shutdown
   - `GET /healthz` handler:
     * Executes Redis PING command via blackboard client
     * Returns `200 OK` with `{"status": "healthy"}` if PING succeeds
     * Returns `503 Service Unavailable` with `{"status": "unhealthy", "error": "..."}` if PING fails

**Changes to the tool execution contract (stdin/stdout):** No changes (deferred to M2.3)

### **2.4. CLI changes**

**New/modified commands:** No changes

**Changes to user output:** No changes

**Rationale:** M2.1 does not integrate with the CLI. The pup binary is created and tested in isolation. CLI integration (launching agent containers) begins in M2.2.

## **3. The 'how': implementation & testing plan**

### **3.1. Key design decisions & risks**

**Key design decisions:**

1. **Mirror orchestrator architecture pattern:** The pup follows the same structural pattern as the orchestrator (`cmd/orchestrator/` and `internal/orchestrator/`), ensuring consistency and maintainability across components.

2. **Full concurrent structure with placeholder work:** The two-goroutine architecture is fully implemented with proper context handling, select loops, and shutdown mechanics, even though the actual work logic is deferred to later milestones. This ensures the concurrent foundation is robust and well-tested before adding complexity.

3. **Fail-fast configuration validation:** All environment variable validation happens at startup, before any Redis connection or goroutine launch. This provides clear, immediate feedback for configuration errors.

4. **Health check simplicity:** The `/healthz` endpoint only validates Redis connectivity (PING command) in M2.1. More sophisticated health checks (e.g., checking specific claim state) are deferred to later milestones.

5. **No operational mode detection:** Following YAGNI principles, M2.1 assumes standard mode only (`replicas: 1`). Controller-worker pattern detection is deferred to Phase 3.

**Potential risks:**

* **Risk:** Goroutine shutdown timing issues or deadlocks during graceful shutdown
  * **Mitigation:** Comprehensive integration tests with signal handling, timeout enforcement (5 seconds max), and explicit verification that all goroutines exit

* **Risk:** Configuration validation gaps leading to runtime failures
  * **Mitigation:** Unit tests covering all validation scenarios (missing vars, empty values, invalid formats)

* **Risk:** Health check endpoint interfering with main engine logic
  * **Mitigation:** Health server runs in separate goroutine with independent lifecycle management

**Alignment with Holt's architectural principles:**
* **Small, single-purpose components:** The pup is focused solely on agent lifecycle management
* **Event-driven architecture:** Goroutine structure is ready for Pub/Sub integration in M2.2
* **Pragmatism over novelty:** Uses standard Go patterns (context, select, channels) without custom abstractions

### **3.2. Implementation steps**

**Phase 1: Package structure and configuration (foundational)**

1. **[Pup]** Create `cmd/pup/main.go` with basic entrypoint structure
2. **[Pup]** Implement `internal/pup/config.go`:
   - Define `Config` struct with required fields
   - Implement `LoadConfig()` to read environment variables
   - Implement `Validate()` with comprehensive validation logic
   - Add unit tests for all validation scenarios
3. **[Pup]** Verify configuration loading with unit tests (90%+ coverage)

**Phase 2: Health check endpoint**

4. **[Pup]** Implement `internal/pup/health.go`:
   - Define `HealthServer` struct
   - Implement `NewHealthServer()` constructor
   - Implement `/healthz` handler with Redis PING logic
   - Implement `Start()` and `Shutdown()` methods
5. **[Pup]** Add unit tests for health handler logic
6. **[Pup]** Add integration test: Start health server, verify 200/503 responses

**Phase 3: Concurrent engine structure**

7. **[Pup]** Implement `internal/pup/engine.go`:
   - Define `Engine` struct
   - Implement `New()` constructor
   - Implement `Start()` method with goroutine launching
   - Implement placeholder `claimWatcher()` with proper select loop
   - Implement placeholder `workExecutor()` with proper select loop
8. **[Pup]** Add unit tests for engine creation and initialization
9. **[Pup]** Add integration test: Start engine, verify both goroutines running, trigger shutdown, verify clean exit

**Phase 4: Main entrypoint and signal handling**

10. **[Pup]** Complete `cmd/pup/main.go`:
    - Load configuration via `LoadConfig()`
    - Create blackboard client connection
    - Create and start health server
    - Create and start engine with context
    - Set up signal handling (SIGINT, SIGTERM)
    - Implement graceful shutdown sequence
11. **[Pup]** Add integration test: Run full pup binary as subprocess, send SIGTERM, verify clean exit within 5 seconds

**Phase 5: Build system and documentation**

12. **[Build]** Add Makefile targets:
    - `build-pup`: Compile pup binary
    - `test-pup`: Run pup unit and integration tests
    - Update `all` target to include pup
13. **[Docs]** Add inline documentation (GoDoc comments) for all exported types and functions
14. **[Docs]** Update `README.md` if necessary with pup binary information

### **3.3. Performance & resource considerations**

**Resource usage:**
* **Memory:** Minimal (<10 MB) - two goroutines with placeholder work, one HTTP server, one Redis connection
* **CPU:** Negligible - goroutines are mostly idle in M2.1 (placeholder work only logs periodically)
* **Network:** Single persistent Redis connection for health checks (PING every ~30 seconds or on-demand via `/healthz`)
* **Storage:** None - no file I/O in M2.1

**Scalability limits:**
* **Single instance:** M2.1 only supports one pup instance per agent container (no controller-worker pattern)
* **Work queue depth:** 1 (single buffered channel) - sufficient for Phase 2's single-agent scenario

**Performance requirements:**
* **Startup time:** <1 second from process start to "ready" state (both goroutines running, health check available)
* **Shutdown time:** <5 seconds for graceful shutdown (context cancellation → goroutine cleanup → process exit)
* **Health check latency:** <100ms for `/healthz` endpoint response (simple Redis PING)

### **3.4. Testing strategy**

**Unit tests:**

Location: `internal/pup/*_test.go`

1. **Configuration validation (`config_test.go`):**
   - Test `LoadConfig()` with valid environment variables (success case)
   - Test `LoadConfig()` with missing `HOLT_INSTANCE_NAME` (error)
   - Test `LoadConfig()` with missing `HOLT_AGENT_NAME` (error)
   - Test `LoadConfig()` with missing `REDIS_URL` (error)
   - Test `LoadConfig()` with empty values (error)
   - Test `Validate()` with valid config (success)
   - Test `Validate()` with invalid config (error)

2. **Health server (`health_test.go`):**
   - Test `NewHealthServer()` constructor
   - Test `/healthz` handler with successful Redis PING (200 OK)
   - Test `/healthz` handler with failed Redis PING (503)
   - Test health server shutdown (verify clean exit)

3. **Engine lifecycle (`engine_test.go`):**
   - Test `New()` constructor
   - Test `Start()` launches both goroutines
   - Test graceful shutdown via context cancellation
   - Test work queue creation (buffer size 1)

**Integration tests:**

Location: `internal/pup/*_test.go` (using testcontainers-go for Redis)

1. **Full pup lifecycle:**
   - Start Redis container via testcontainers-go
   - Set environment variables
   - Run compiled pup binary as subprocess (not containerized)
   - Verify pup starts successfully (check logs or health endpoint)
   - Send HTTP GET to `/healthz`, verify 200 OK response
   - Send SIGTERM signal to pup process
   - Verify pup exits cleanly within 5 seconds
   - Verify no goroutine leaks (check for "leaked goroutine" in logs)

2. **Health check without Redis:**
   - Start pup binary without Redis running
   - Send HTTP GET to `/healthz`, verify 503 response
   - Shutdown pup

3. **Configuration failure scenarios:**
   - Attempt to start pup with missing `HOLT_INSTANCE_NAME`
   - Verify pup exits immediately with error message
   - Repeat for other required environment variables

**Performance tests:**

Not required for M2.1 (minimal resource usage, no performance-critical paths).

**E2E tests (holt tests):**

Not required for M2.1. E2E testing begins in M2.5 when the full single-agent workflow is integrated.

**Test coverage target:** 90%+ for `internal/pup/` package

## **4. Principle compliance check**

### **4.1. YAGNI (You Ain't Gonna Need It)**

**New third-party dependencies:**
* None - uses existing Go standard library and `pkg/blackboard` client

**Justification:**
* The pup uses only battle-tested standard library components (`context`, `net/http`, `os/signal`, `sync`)
* No new external dependencies introduced
* Operational mode detection (controller-worker pattern) is explicitly deferred to Phase 3 (YAGNI)

### **4.2. Auditability**

**New artefacts created:** None in M2.1

**State changes captured:** None in M2.1

**Rationale:** M2.1 is pure infrastructure. The pup does not yet create artefacts or modify blackboard state. Artefact creation begins in M2.3 (basic tool execution).

### **4.3. Small, single-purpose components**

**Component responsibility boundaries:**

The agent pup's single purpose is to manage the lifecycle of an agent instance:
* Connect to the blackboard
* Watch for claims (M2.2+)
* Execute work (M2.3+)
* Report results (M2.3+)

M2.1 establishes the foundational infrastructure without blurring responsibilities. The pup does not:
* Make orchestration decisions (orchestrator's job)
* Manage Docker containers (CLI's job)
* Implement business logic (agent tools' job)

**Component isolation:** The pup is a standalone binary with no compile-time dependencies on orchestrator or CLI code. All communication happens via the blackboard.

### **4.4. Security considerations**

**Attack surfaces:**
* **HTTP health check endpoint:** Read-only, no authentication required (acceptable for internal health checks)
* **Environment variables:** Secrets (e.g., Redis credentials) passed via environment (standard practice for containerized apps)

**Data exposure risks:**
* **Minimal:** Health check only exposes Redis connectivity status (no sensitive data)
* **Logs:** Standard Go logging may include configuration values - verify no secrets are logged

**Container isolation:**
* Not applicable in M2.1 - container integration begins in M2.2

**Network communications:**
* **Redis connection:** Assumes trusted network (Redis should not be exposed publicly)
* **Health check HTTP:** Listens on localhost only (not externally accessible)

**Security recommendations for M2.1:**
* Do NOT log `REDIS_URL` if it contains credentials
* Health endpoint should bind to `localhost:8080` (not `0.0.0.0`)

### **4.5. Backward compatibility**

**API/data structure changes:** None - this is a new component

**Existing workflows preserved:** Yes - no changes to CLI, orchestrator, or blackboard

**Feature additive:** Yes - M2.1 is purely additive, introducing the pup without modifying existing components

**Deprecation path:** Not applicable (new component)

**Compatibility impact:** None - M2.1 has zero impact on existing Phase 1 functionality

### **4.6. Dependency impact**

**Redis usage changes:**
* **New pattern:** Agent pup connects to the same Redis instance as orchestrator and CLI
* **Connection pooling:** Uses existing `pkg/blackboard` client (already tested in M1.2)
* **No new Redis requirements:** Same Redis version and configuration as Phase 1

**Docker/container requirements:**
* Not applicable in M2.1 - container packaging begins in M2.2

**Go version:**
* **No change:** Uses same Go version as existing codebase (likely Go 1.21+)
* **No new language features:** Uses standard concurrency patterns (goroutines, channels, context)

**Build dependencies:**
* **No new build tools:** Uses existing Makefile pattern
* **No new test dependencies:** Uses existing `testcontainers-go` from M1.2

**Development environment impact:**
* **No change:** Developers can compile and test pup with existing Go toolchain
* **No new system dependencies:** No additional packages or tools required

**CI/CD pipeline impact:**
* **Minimal:** New Makefile target (`build-pup`) integrates with existing build system
* **Test execution:** New tests run in parallel with existing test suites

## **5. Definition of done**

*This checklist must be fully satisfied for the milestone to be considered complete.*

* [ ] All implementation steps from section 3.2 are complete
* [ ] All tests defined in section 3.4 are implemented and passing
* [ ] Performance requirements from section 3.3 are met and verified:
  * [ ] Startup time <1 second
  * [ ] Shutdown time <5 seconds
  * [ ] Health check latency <100ms
* [ ] Overall test coverage has not decreased (project-wide)
* [ ] `internal/pup/` package has 90%+ test coverage
* [ ] The Makefile has been updated with `build-pup` and `test-pup` targets
* [ ] All new code has GoDoc comments for exported types and functions
* [ ] The developer onboarding time (git clone to running holt up) remains under 10 minutes
* [ ] All TODOs from the specification documents relevant to this milestone have been resolved
* [ ] All failure modes identified in section 6.1 have been implemented and tested
* [ ] Concurrency considerations from section 6.2 have been addressed
* [ ] All open questions from section 7 have been resolved or documented as future work
* [ ] AI agent implementation guidance has been followed and integration checklist completed
* [ ] Security considerations from section 4.4 have been addressed and validated:
  * [ ] Health endpoint binds to localhost only
  * [ ] No secrets logged in configuration loading
* [ ] Backward compatibility requirements from section 4.5 are satisfied (N/A - new component)
* [ ] Dependency impact analysis from section 4.6 has been completed and approved
* [ ] Operational readiness checklist from section 9 is fully satisfied

## **6. Error scenarios & edge cases**

### **6.1. Failure modes**

**Configuration failures (fail-fast at startup):**

1. **Missing required environment variable:**
   - **Scenario:** `HOLT_INSTANCE_NAME` not set
   - **Expected behavior:** Pup exits immediately with error message: "HOLT_INSTANCE_NAME environment variable is required"
   - **Exit code:** Non-zero (1)
   - **Testing:** Unit test in `config_test.go`

2. **Empty environment variable value:**
   - **Scenario:** `HOLT_AGENT_NAME=""` (empty string)
   - **Expected behavior:** Pup exits with error: "HOLT_AGENT_NAME cannot be empty"
   - **Exit code:** Non-zero (1)
   - **Testing:** Unit test in `config_test.go`

3. **Invalid Redis URL format:**
   - **Scenario:** `REDIS_URL="not-a-url"`
   - **Expected behavior:** Pup exits with error: "Invalid REDIS_URL format"
   - **Exit code:** Non-zero (1)
   - **Testing:** Unit test in `config_test.go`

**Redis connection failures (runtime):**

4. **Redis unavailable at startup:**
   - **Scenario:** Redis container not running or network unreachable
   - **Expected behavior:** Pup starts successfully but health check returns 503
   - **Retry logic:** Health check retries PING on each HTTP request (no background retry in M2.1)
   - **Testing:** Integration test with Redis stopped

5. **Redis connection lost during operation:**
   - **Scenario:** Redis container stops while pup is running
   - **Expected behavior:** Health check transitions to 503 status
   - **Goroutine impact:** Goroutines continue running (placeholder work does not require Redis in M2.1)
   - **Testing:** Integration test with Redis restart scenario

**Graceful shutdown failures:**

6. **Shutdown timeout exceeded:**
   - **Scenario:** Goroutines do not exit within 5 seconds after context cancellation
   - **Expected behavior:** Main process forcefully exits after timeout (log warning)
   - **Prevention:** Select loops in goroutines must respond to `ctx.Done()` immediately
   - **Testing:** Integration test with shutdown timeout verification

7. **Multiple shutdown signals:**
   - **Scenario:** User sends SIGINT, then SIGTERM rapidly
   - **Expected behavior:** First signal triggers graceful shutdown, subsequent signals are no-ops (context already cancelled)
   - **Testing:** Integration test with multiple signals

**Health check failures:**

8. **Health endpoint unreachable:**
   - **Scenario:** Port 8080 already in use by another process
   - **Expected behavior:** Pup fails to start with error: "Failed to start health server: address already in use"
   - **Exit code:** Non-zero (1)
   - **Testing:** Integration test with port conflict

### **6.2. Concurrency considerations**

**Race conditions:**

1. **Work queue channel access:**
   - **Scenario:** Claim Watcher writes to work queue while Work Executor reads
   - **Mitigation:** Go channels are inherently thread-safe (no explicit locking needed)
   - **Testing:** Run tests with `-race` flag to detect race conditions

2. **Shutdown context cancellation:**
   - **Scenario:** Main goroutine cancels context while worker goroutines are in select loops
   - **Mitigation:** All goroutines use `select` with `case <-ctx.Done()` to detect cancellation
   - **Testing:** Integration test verifies clean shutdown under load

3. **Blackboard client concurrent access:**
   - **Scenario:** Health check handler and goroutines access blackboard client simultaneously
   - **Mitigation:** `pkg/blackboard` client must be thread-safe (verify in M1.2 implementation)
   - **Assumption:** Redis client library (go-redis) is thread-safe
   - **Testing:** Unit test in M1.2 should verify thread safety

**Deadlock scenarios:**

4. **Work queue blocking on shutdown:**
   - **Scenario:** Claim Watcher tries to write to work queue, but Work Executor already exited
   - **Mitigation:** Claim Watcher select loop includes `ctx.Done()` case to abort send operation
   - **Testing:** Integration test with shutdown during claim processing (M2.2+)

5. **Health server shutdown hanging:**
   - **Scenario:** Health server `Shutdown()` waits indefinitely for in-flight requests
   - **Mitigation:** Use `context.WithTimeout()` for health server shutdown (5-second max)
   - **Testing:** Integration test with active health check request during shutdown

**Goroutine leaks:**

6. **Goroutines not exiting on shutdown:**
   - **Scenario:** Select loop missing `ctx.Done()` case or goroutine blocked on channel
   - **Prevention:** All goroutines must have explicit `ctx.Done()` handling
   - **Detection:** Integration tests verify process exits cleanly (no hanging goroutines)
   - **Testing:** Use `goleak` library or process inspection to detect leaks

### **6.3. Edge case handling**

**Empty or minimal inputs:**

1. **No claims available (expected in M2.1):**
   - **Scenario:** Pup starts but no claims exist on blackboard
   - **Expected behavior:** Claim Watcher runs indefinitely, logging periodically
   - **Testing:** Integration test verifies pup runs stably with no claims

2. **Work queue never receives data:**
   - **Scenario:** Work Executor goroutine runs but work queue remains empty
   - **Expected behavior:** Goroutine blocks on channel receive, responds to shutdown
   - **Testing:** Integration test verifies shutdown works even with empty queue

**Maximum scale scenarios:**

3. **Many rapid shutdown signals:**
   - **Scenario:** User sends 100 SIGINT signals in rapid succession
   - **Expected behavior:** First signal triggers shutdown, remaining signals ignored
   - **Testing:** Integration test with signal flood

4. **Health check request flood:**
   - **Scenario:** 1000 concurrent HTTP requests to `/healthz`
   - **Expected behavior:** All requests handled (may be slow, but no crashes)
   - **Mitigation:** HTTP server has default connection limits
   - **Testing:** Load test with `ab` (Apache Bench) or `vegeta`

**Network partitions or timeouts:**

5. **Redis PING timeout:**
   - **Scenario:** Redis PING command hangs for 30+ seconds
   - **Mitigation:** Set Redis client timeout to 5 seconds max
   - **Expected behavior:** Health check returns 503 after timeout
   - **Testing:** Integration test with Redis network delay simulation

6. **Health check HTTP timeout:**
   - **Scenario:** Client request to `/healthz` times out
   - **Expected behavior:** HTTP server responds within timeout or client abandons request
   - **Mitigation:** No server-side handling needed (client's responsibility)

**Resource exhaustion scenarios:**

7. **Out of memory (unlikely in M2.1):**
   - **Scenario:** System runs out of available memory
   - **Expected behavior:** OS kills pup process (no graceful handling possible)
   - **Prevention:** M2.1's minimal resource usage makes this highly unlikely

8. **File descriptor exhaustion:**
   - **Scenario:** No available file descriptors for Redis connection
   - **Expected behavior:** Pup fails to start with error: "Failed to connect to Redis: too many open files"
   - **Prevention:** M2.1 only opens minimal FDs (Redis, HTTP server)

## **7. Open questions & decisions**

**Q1: Health check port configuration**
- **Question:** Should the health check port be configurable via environment variable (`HOLT_HEALTH_PORT`) or hardcoded to 8080?
- **Recommendation:** Hardcode to 8080 for M2.1 (YAGNI). Add configuration in later milestone if needed for Kubernetes integration.
- **Status:** Awaiting decision

**Q2: Logging framework**
- **Question:** Should we use structured logging (e.g., `zerolog`, `zap`) or standard `log` package?
- **Recommendation:** Use standard `log` package for M2.1 (YAGNI). Upgrade to structured logging in Phase 3 if operational needs require it.
- **Status:** Awaiting decision

**Q3: Goroutine placeholder work frequency**
- **Question:** How frequently should placeholder goroutines log status (every 1 second, 10 seconds, 1 minute)?
- **Recommendation:** Log every 30 seconds to prove liveness without spamming logs.
- **Status:** Awaiting decision

**Q4: Work queue buffer size justification**
- **Question:** Why buffer size 1 instead of 0 (unbuffered) or larger?
- **Rationale:** Buffer size 1 allows Claim Watcher to post one claim without blocking, while preventing unbounded queue growth. Phase 2 only has one agent, so larger buffers are unnecessary.
- **Status:** Design decision documented (no blocker)

## **8. AI agent implementation guidance**

### **8.1. Development approach**

**Start with the simplest path that satisfies success criteria:**

1. **Configuration first:** Implement and test `config.go` completely before touching any other code. This ensures the pup can load its identity and connection details correctly.

2. **Health check second:** Build the health server as a standalone component. Test it in isolation before integrating with the main engine.

3. **Engine structure third:** Implement the engine with placeholder goroutines. Focus on getting the concurrent architecture correct (context, select loops, shutdown) before adding real work logic.

4. **Integration last:** Wire everything together in `main.go`. Test the full lifecycle (start → health check → shutdown) as a subprocess.

**Implement comprehensive error handling from the beginning:**

* Every environment variable load must have explicit error checking
* Every Redis connection attempt must handle failure gracefully
* Every goroutine must have a clear shutdown path (no infinite loops without `ctx.Done()` checks)

**Write tests before implementation (TDD approach):**

* For configuration: Write unit tests for all validation scenarios first, then implement `LoadConfig()` to pass them
* For health check: Write integration test with Redis, then implement health handler
* For engine: Write test for graceful shutdown, then implement goroutine select loops

**Use defensive programming - validate all inputs and assumptions:**

* Validate environment variables are non-empty strings
* Validate Redis URL format before attempting connection
* Verify goroutines exit cleanly in tests (check process termination)

### **8.2. Common pitfalls to avoid**

**Forgetting to handle Redis connection failures:**
* **Pitfall:** Assuming Redis is always available at startup
* **Solution:** Health check must tolerate Redis being unavailable and return 503 gracefully

**Missing container cleanup in error scenarios:**
* **Not applicable in M2.1** (no container integration yet)
* **Relevant in M2.2+**

**Inadequate input validation in CLI commands:**
* **Not applicable in M2.1** (no CLI integration yet)

**Breaking existing workflows during integration:**
* **Risk:** M2.1 should not modify orchestrator or CLI behavior
* **Verification:** Run existing Phase 1 tests to ensure no regressions

**Goroutine select loop mistakes:**
* **Pitfall:** Forgetting to include `case <-ctx.Done()` in select loop
* **Result:** Goroutine hangs on shutdown
* **Solution:** Every select loop must have context cancellation case

**Channel blocking on shutdown:**
* **Pitfall:** Trying to send to work queue after receiver goroutine exits
* **Solution:** Use `select` with `ctx.Done()` when sending to channel:
  ```go
  select {
  case workQueue <- claim:
      // Successfully sent
  case <-ctx.Done():
      // Shutdown initiated, abort send
      return
  }
  ```

**Race conditions in tests:**
* **Pitfall:** Not running tests with `-race` flag
* **Solution:** Always run `go test -race ./...` to detect data races

**Logging secrets:**
* **Pitfall:** Logging `REDIS_URL` which may contain passwords
* **Solution:** Redact credentials before logging connection strings

### **8.3. Integration checklist**

**Pre-implementation verification:**

* [ ] All prerequisite features are complete:
  * [ ] M1.1: Redis Blackboard Foundation (✅ completed)
  * [ ] M1.2: Blackboard Client Operations (✅ completed)
* [ ] No breaking changes to existing contracts:
  * [ ] `pkg/blackboard` API remains unchanged
  * [ ] Orchestrator behavior unaffected
  * [ ] CLI commands work as before
* [ ] New data structures are backward compatible:
  * [ ] No new blackboard data structures in M2.1
* [ ] All component interfaces remain stable:
  * [ ] Blackboard client interface unchanged
  * [ ] No new interfaces introduced in M2.1

**Post-implementation verification:**

* [ ] All Phase 1 tests still pass (no regressions)
* [ ] New pup tests pass with `-race` flag
* [ ] Health check endpoint accessible via `curl http://localhost:8080/healthz`
* [ ] Pup binary can be killed with SIGTERM and exits cleanly
* [ ] No goroutine leaks detected in tests

## **9. Operational readiness**

### **9.1. Monitoring and observability**

**Metrics to track:**
* **Health status:** HTTP 200 vs 503 response rate from `/healthz`
* **Uptime:** Duration since pup process started
* **Goroutine count:** Should remain constant (2 goroutines in M2.1)

**Log messages:**
* **Startup:** `[INFO] Agent pup starting for agent='go-coder' instance='my-holt'`
* **Redis connection:** `[INFO] Connected to Redis at redis://...`
* **Health check:** `[DEBUG] Health check: Redis PING successful`
* **Shutdown:** `[INFO] Shutdown signal received, initiating graceful shutdown`
* **Goroutine exit:** `[DEBUG] Claim Watcher exited cleanly`

**Structured logging events (if using structured logging):**
* Not required in M2.1 (standard `log` package recommended)
* Can be added in later milestone if needed

**Health check modifications:**
* M2.1 health check is basic (Redis PING only)
* Future enhancements (M2.3+): Include claim processing status, last execution time

**Issue detection and diagnosis:**
* **Pup not starting:** Check environment variables via `docker logs <pup-container>`
* **Health check failing:** Verify Redis connectivity via `redis-cli PING`
* **Pup not shutting down:** Check for goroutine deadlocks (send SIGKILL if needed)

### **9.2. Rollback and disaster recovery**

**Feature disable via configuration:**
* Not applicable in M2.1 - pup is a new binary, not a feature toggle

**Rollback procedure if feature causes issues:**
1. Stop agent containers (M2.2+ - no containers in M2.1)
2. Revert to previous git commit
3. Rebuild orchestrator and CLI (pup not yet integrated)
4. Restart holt instance

**Data migration or cleanup requirements:**
* None - M2.1 does not modify blackboard state

**Recovery time objective:**
* **RTO:** Instant (no state to recover in M2.1)
* **RPO:** N/A (no data loss possible in M2.1)

### **9.3. Documentation and training**

**CLI command documentation:**
* Not applicable in M2.1 - pup is not invoked directly by users

**Feature coverage in user guides:**
* Not applicable in M2.1 - internal component only

**API documentation:**
* **GoDoc comments:** All exported types and functions in `internal/pup/` must have clear documentation
* **Health endpoint:** Document `/healthz` response format in code comments

**Troubleshooting guides:**
* **Problem:** Pup exits immediately with "HOLT_INSTANCE_NAME environment variable is required"
  * **Solution:** Ensure all required environment variables are set
* **Problem:** Health check returns 503
  * **Solution:** Verify Redis is running and accessible at `REDIS_URL`
* **Problem:** Pup hangs on shutdown
  * **Solution:** Send SIGKILL after 10 seconds, report bug (should never happen)

**Team training requirements:**
* None - M2.1 is foundational infrastructure

## **10. Self-validation checklist**

### **Before starting implementation:**

* [ ] I understand how this feature aligns with the current phase (Phase 2: Single Agent)
* [ ] All success criteria (section 1.3) are measurable and testable
* [ ] I have considered every component in section 2 explicitly
* [ ] All design decisions (section 3.1) are justified and documented
* [ ] I understand the two-goroutine architecture from `design/agent-pup.md`
* [ ] I have reviewed the orchestrator implementation pattern for consistency

### **During implementation:**

* [ ] I am implementing the simplest solution that meets success criteria
* [ ] All error scenarios (section 6) are being handled, not just happy path
* [ ] Tests are being written before or alongside code (TDD approach)
* [ ] I am validating that existing functionality is not broken (run Phase 1 tests)
* [ ] All select loops include `case <-ctx.Done()` for graceful shutdown
* [ ] No secrets (Redis credentials) are being logged

### **Before submission:**

* [ ] All items in Definition of Done (section 5) are complete
* [ ] Feature has been tested in a clean environment from scratch
* [ ] All tests pass with `-race` flag (no race conditions)
* [ ] Documentation is updated and accurate (GoDoc comments)
* [ ] I have considered the operational impact (section 9) of this feature
* [ ] Health check endpoint is accessible and returns correct responses
* [ ] Pup responds to SIGTERM and exits within 5 seconds
* [ ] No goroutine leaks detected (process exits cleanly)
